{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58768f7d-1138-477e-92c1-9c692954cad0",
   "metadata": {},
   "source": [
    "# Suivis Projet Info : Stellar Analytics\n",
    "#### Axelle Refeyton . Jean Roelens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2086a81-d853-428c-b0a8-26839441c19c",
   "metadata": {},
   "source": [
    "Le but de se projet est initialement de permettre à un utilisateur de prendre une photo d'une étoile et de retrouver des informations dessus, notamment sont nom, sa position ainsi que sa composition chimique qui peux être récupérer en fonction de son spectre lumineux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af42a8-2fb6-4ef2-a41b-98cb2ecd6808",
   "metadata": {},
   "source": [
    "Ressources utilisées : \n",
    "- [NIST Spectra Database](https://physics.nist.gov/PhysRefData/ASD/lines_form.html)\n",
    "- [Documentation sur les spectres lumineux](https://atomic-spectra.net/)\n",
    "- [Simbad, DB d'étoiles communautaire open source](https://simbad.u-strasbg.fr/simbad/)\n",
    "- [MAST portal](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html)\n",
    "- [Raies de Fraunhofer](https://fr.wikipedia.org/wiki/Raies_de_Fraunhofer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6325db-18bc-4b28-b676-bc19ea9c5709",
   "metadata": {},
   "source": [
    "En début de projet beaucoup de temps fut consacré à de la recherche de documentation ainsi que de jeux de données. Egalement nous avons eu l'occasion de nous entretenir lors d'une conférence Zoom avec deux membres du CNES (Orphée Faucoz et Denis Standarovski) travaillant depuis plusieurs années sur un sujet similaire : L'identification d'exoplanétes en utilisant les spectres d'absorption.\n",
    "\n",
    "Au cours de l'entretien ils nous ont clairement expliqué que ce que l'on souhaiter faire êtait une tâche difficile et que cela nécessité du temps ne serait-ce que pour la compréhension de l'environnement dans lequel nous naviguons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35fc5e2-2628-441a-87cd-2f9d22d8b6e8",
   "metadata": {},
   "source": [
    "On a parcouru beaucoup de base de données gratuite et d'autres non afin de trouver celles qui correspondrait au mieux à nos besoins. Au final on a retenue Simbad pour la récupération des spectres émis par les étoiles et NIST pour récupérer le spectre d'émissions des élèments que peuvent composer une étoile, càd : Oxygéne, Hydrogénes, Sodium, Hélium, Mercure, Fer, Magnésium, Calcium, Titane et finalement Nickel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a24c9c-0c4e-44ef-b8a0-8c14af6a3864",
   "metadata": {},
   "source": [
    "à partir de ce moment on a divisé la structure du projet en deux parties, une partie objet céleste (gérer par Axelle Refeyton) et une partie spectre chimique (gérer par Jean Roelens). Ensuite chaque partie est divisés en étapes afin de faciliter le procéder de réalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f12ba1-c599-458f-9b82-a09f45378a7a",
   "metadata": {},
   "source": [
    "## Objet Céleste (A.Refeyton)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b40faf0a-bc67-4fcd-8688-46f61c195dea",
   "metadata": {},
   "source": [
    "à remplir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac218d2a-038a-451d-8f66-eecd2f59a138",
   "metadata": {},
   "source": [
    "## Spectre Chimique (J.Roelens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a406d77-7e3a-41ee-b726-c2fa84c8570c",
   "metadata": {},
   "source": [
    "L'objectif de cette partie est :\n",
    "1. **Pour chaque élèments récupérer les différentes ionization possible.**\n",
    "2. **Extraire le tableau de spectre depuis NIST (en utilisant un scrapper)**\n",
    "3. **Le formatter pour récupérer que les lignes fortes**\n",
    "4. **Créer un dataset par élément et ionization avec les lignes fortes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b966b437-d2a5-4089-a17e-b215984f6c32",
   "metadata": {},
   "source": [
    "Pour commencer il faut que je récupére les ionizations de chaque élèments, étant une étape pas forcément très complexe j'ai préféré le faire à la main en m'aidant de [atomic-spectra](https://atomic-spectra.net/spectrum.php) et des [Raies de Fraunhofer](https://fr.wikipedia.org/wiki/Raies_de_Fraunhofer) On en sort cette liste : \n",
    "- Oxygéne [I, II, III, IV, V, VI, VII, VIII]\n",
    "- Hydrogénes [I]\n",
    "- Sodium [I, II, III, IV, V, VI, VII, VIII, IX, X, XI]\n",
    "- Hélium [I, II]\n",
    "- Mercure [I, II, III]\n",
    "- Fer [I, II ,III , IV, V, VI, VII, VIII, IX, X, XI, XII, XIII, XIV, XV, XVI, XVII, XVIII, XIX, XX, XXI, XXII, XXIII, XXIV, XXV, XVI]\n",
    "- Magnésium [I, II, III, IV, V, VI, VII, VIII, IX, X, XI, XII]\n",
    "- Calcium [I, II, III, IV, V, VI, VII, VIII, IX, X, XI, XII, XIII, XIV, XV, XVI]\n",
    "- Titane [I, II, III, IV, V, VI, VII, VIII, IX, X, XI, XII, XIII, XIV, XV, XVI, XVII, XVIII, XIX, XX, XXI, XXII]\n",
    "- Nickel [I, II, III, IV, V, VI, VII, VIII, IX, X, XI, XII, XIII, XIV, XV, XVI, XVII, XVIII, XIX, XX, XXI, XXII, XXIII, XXIV, XXV, XXVI, XXVII, XXVIII]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3d45b-1c60-44aa-8a72-110b98ef1fe0",
   "metadata": {},
   "source": [
    "Maintenant que l'étape facile est faites je vais pouvoir m'attaquer à l'étape plus hardu d'extraire les données depuis NIST. L'idée global dérriére est de récupérer le HTML de la page NIST en donnant dans l'URL du site l'élèment ainsi que son indice de ionization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64242ce2-f0d6-48bb-a0e0-e8622f0c863b",
   "metadata": {},
   "source": [
    "En saisissant H I (pour Hydrogénes Ionization 1) on obtiens cet URL :\n",
    "\n",
    "https://physics.nist.gov/cgi-bin/ASD/lines1.pl?spectra=H+I&output_type=0&low_w=&upp_w=&unit=1&submit=Retrieve+Data&de=0&plot_out=0&I_scale_type=1&format=0&line_out=0&en_unit=0&output=0&bibrefs=1&page_size=15&show_obs_wl=1&show_calc_wl=1&unc_out=1&order_out=0&max_low_enrg=&show_av=2&max_upp_enrg=&tsb_value=0&min_str=&A_out=0&intens_out=on&max_str=&allowed_out=1&forbid_out=1&min_accur=&min_intens=&conf_out=on&term_out=on&enrg_out=on&J_out=on\n",
    "\n",
    "Plutôt long, mais ce qui est assez intéressant que beaucoup de paramètres pourront-être passé assez facilement par celles-ci comparons avec l'URL de O I pour voir ou nous devrons saisir l'élèment et l'ionization \n",
    "\n",
    "https://physics.nist.gov/cgi-bin/ASD/lines1.pl?spectra=O+I&output_type=0&low_w=&upp_w=&unit=1&submit=Retrieve+Data&de=0&plot_out=0&I_scale_type=1&format=0&line_out=0&en_unit=0&output=0&bibrefs=1&page_size=15&show_obs_wl=1&show_calc_wl=1&unc_out=1&order_out=0&max_low_enrg=&show_av=2&max_upp_enrg=&tsb_value=0&min_str=&A_out=0&intens_out=on&max_str=&allowed_out=1&forbid_out=1&min_accur=&min_intens=&conf_out=on&term_out=on&enrg_out=on&J_out=on\n",
    "\n",
    "Comme on peut le voir l'élèment se trouve en début d'URL essayons cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea233f17-d499-4df2-89d1-5b2b3309b5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succés de la requéte\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "START_URL = r\"https://physics.nist.gov/cgi-bin/ASD/lines1.pl?spectra=\"\n",
    "END_URL = r\"&output_type=0&low_w=&upp_w=&unit=1&submit=Retrieve+Data&de=0&plot_out=0&I_scale_type=1&format=0&line_out=0&en_unit=0&output=0&bibrefs=1&page_size=15&show_obs_wl=1&show_calc_wl=1&unc_out=1&order_out=0&max_low_enrg=&show_av=2&max_upp_enrg=&tsb_value=0&min_str=&A_out=0&intens_out=on&max_str=&allowed_out=1&forbid_out=1&min_accur=&min_intens=&conf_out=on&term_out=on&enrg_out=on&J_out=on\"\n",
    "\n",
    "# Essayons de voir si on peut obtenir un code 200, mais avant cela construisons notre URL de maniére naïve pour ce test\n",
    "\n",
    "URL = START_URL + \"Ni+X\" + END_URL\n",
    "\n",
    "resp = requests.get(URL)\n",
    "if resp.status_code == 200:\n",
    "    print(f\"Succés de la requéte\")\n",
    "else :\n",
    "    print(f\"Echec de la requéte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f9639-5a69-4c45-880c-36843c45eb3a",
   "metadata": {},
   "source": [
    "Maintenant que notre approche naïve fonctionne vérifions que l'intégralité des élèments et ionization fonctionne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac395e4a-0267-466a-87a6-86253e94f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le fait que je marque certaines \"variables\" en majuscules est simplement un tic pour m'indiquer qu'il s'agit de constante\n",
    "ELEMENT_DICT = {\n",
    "    \"O\" : [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\",\"VII\"],\n",
    "    \"H\" : [\"I\"],\n",
    "    \"Na\" : [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\",\"VII\",\"VIII\",\"IX\",\"X\",\"XI\"],\n",
    "    \"He\" : [\"I\",\"II\"],\n",
    "    \"Hg\" : [\"I\",\"II\",\"III\"],\n",
    "    \"Fe\" : [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\",\"VII\",\"VIII\",\"IX\",\"X\",\"XI\",\"XII\",\"XIII\",\"XIV\",\"XV\",\"XVI\"],\n",
    "    \"Mg\" : [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\",\"VII\",\"VIII\",\"IX\",\"X\",\"XI\",\"XII\"],\n",
    "    \"Ca\" : [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\",\"VII\",\"VIII\",\"IX\",\"X\",\"XI\",\"XII\",\"XIII\",\"XIV\",\"XV\",\"XVI\"],\n",
    "    \"Ti\" : [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\",\"VII\",\"VIII\",\"IX\",\"X\",\"XI\",\"XII\",\"XIII\",\"XIV\",\"XV\",\"XVI\",\"XVII\",\"XVIII\",\"XIX\",\"XX\",\"XXI\",\"XXII\"],\n",
    "    \"Ni\" : [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\",\"VII\",\"VIII\",\"IX\",\"X\",\"XI\",\"XII\",\"XIII\",\"XIV\",\"XV\",\"XVI\",\"XVII\",\"XVIII\",\"XIX\",\"XX\",\"XXI\",\"XXII\",\"XXIII\",\"XXIV\",\"XXV\",\"XXVI\",\"XXVII\",\"XXVIII\"]\n",
    "}\n",
    "\n",
    "# Je vérifie la longueur de chacune des clès pour être sur de ne pas avoir fait d'erreur \n",
    "def element_dict_verification():\n",
    "    for key in ELEMENT_DICT.keys():\n",
    "        print(f\"Elément : {key} Len : {len(ELEMENT_DICT[key])}\")\n",
    "\n",
    "# Et ensuite on test les requêtes\n",
    "\n",
    "def get_200(r : requests.models.Response):\n",
    "    if r.status_code != 200:\n",
    "        return False\n",
    "    return True\n",
    "def multi_request_verification(d : dict):\n",
    "    for k in d.keys():\n",
    "        for v in range(len(d[k])):\n",
    "            url = START_URL + k + \"+\" + d[k][v] + END_URL\n",
    "            if not get_200(requests.get(url)):\n",
    "                print(f\"Error with el : {k} and ionization : {d[k][v]}\")\n",
    "            else : \n",
    "                print(f\"Success with el : {k} and ionization : {d[k][v]}\")\n",
    "# multi_request_verification(ELEMENT_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627647d4-82fe-42b8-8a00-f0e6ccbf6967",
   "metadata": {},
   "source": [
    "Ok on dirait bien qu'on a que des codes 200 pour l'ensemble des requêtes ! Malheuresement on se rendra compte plus tard que NIST renvoie des code 200 même en cas de mauvais URL. Le seul moyen de savoir si la requête a bien aboutit et de récupérer le tableau **\"\\<table>\"** qui va contenir les données qui nous intéresse. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21043a9-2811-486b-98cd-4ba61a3f02ff",
   "metadata": {},
   "source": [
    "L'idée va être de voir si on peut récupérer la balise \"table\" contenant le styling que nous cherchons pour chaque lien avec l'aide de la librairie que nous allons le plus utiliser durant notre partie : \"BeautifulSoup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9296ef13-88de-40be-910d-ef301b2ee57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "\n",
    "# Vu que je vais beaucoup utiliser request autant se créer des petites fonctions QOL (Quality Of Life)\n",
    "\n",
    "def url_builder(d : dict):\n",
    "    resp = {}\n",
    "    for key in d.keys():\n",
    "        for v in d[key]:\n",
    "            resp[key+v] = START_URL + key + \"+\" + v + END_URL\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69f595db-6b41-43ab-a833-49a9f70a04d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'OI': No scheme supplied. Perhaps you meant https://OI?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m urls \u001b[38;5;241m=\u001b[39m url_builder(ELEMENT_DICT)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[1;32m----> 3\u001b[0m     req \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(req\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m     tables \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[0;32m    564\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[0;32m    565\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    573\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[0;32m    574\u001b[0m )\n\u001b[1;32m--> 575\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    579\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[0;32m    580\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[0;32m    581\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:486\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    483\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    485\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[1;32m--> 486\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:368\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_method(method)\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:439\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;241m*\u001b[39me\u001b[38;5;241m.\u001b[39margs)\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No scheme supplied. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    442\u001b[0m     )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No host supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mMissingSchema\u001b[0m: Invalid URL 'OI': No scheme supplied. Perhaps you meant https://OI?"
     ]
    }
   ],
   "source": [
    "urls = url_builder(ELEMENT_DICT)\n",
    "for url in urls:\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    target_table = [table for table in tables if 'background-color:#FFFEEE;' in table.get('style', '')]\n",
    "    if len(target_table) != 1:\n",
    "        print(f'error with url : {url}')\n",
    "    else :\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71520cd3-a275-4eb9-9401-4b0308d83023",
   "metadata": {},
   "source": [
    "On voit donc désormais que deux lien sont *mort* celui pour le Nickel 6 et le Nickel 8. Hormis ça l'ensemble des autres liens marche. Pour la prochaine étape il nous faut récupérer toute les rows contenant une donnée dans la colonne *Observed Wavelength Vac (nm)* ainsi que *Rel. Int.* C'est les deux colonnes qui nous intéresse pour la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c388a7a5-8be8-4377-b7ad-1b8203d6dddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       wavelength intensities chemical\n",
      "count         174         174      174\n",
      "unique        157          48        1\n",
      "top       94.8686         120      O I\n",
      "freq            3          18      174\n"
     ]
    }
   ],
   "source": [
    "# Pour commencer passont la logique précédente en fonction \n",
    "\n",
    "def get_table(req : requests.models.Response):\n",
    "    soup = BeautifulSoup(req.text,'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    target_table = [table for table in tables if 'background-color:#FFFEEE;' in table.get('style', '')]\n",
    "    if len(target_table) > 0 :\n",
    "        return target_table[0]\n",
    "    else :\n",
    "        return None\n",
    "\n",
    "# On va traiter seulement le premier question de rapidité depuis python 3.6 les dicts sont ordonnées du coup le premier élèment sera toujours OI\n",
    "urls = url_builder(ELEMENT_DICT)\n",
    "oxygen_one = list(urls.items())[0]\n",
    "table = get_table(requests.get(oxygen_one[1]))\n",
    "# Maintenant on va \"drill down\" la table afin d'obtenir tout les Tbody puis les Tr qui nous intéressent.\n",
    "tbodies = table.find_all('tbody')\n",
    "# Seul les tbody pair nous intéresse car ils contiennent la data en question\n",
    "evenTBodies = tbodies[1::2]\n",
    "# Ensuite pour chaque tbody on veut récupérer toute les balises tr\n",
    "# firstTBody = evenTBodies[0]\n",
    "# Holder pour les values récupéré afin d'en faire un dataframe par la suite\n",
    "All_Observed_Wavelength = []\n",
    "All_Relative_Intensities = []\n",
    "\n",
    "# for tbody in evenTBodies :\n",
    "#     for tr in tbody.find_all('tr'):\n",
    "#         all_td = tr.find_all('td')\n",
    "#         if len(all_td) >= 2:\n",
    "#             Obs_Wav = all_td[0].text.strip()\n",
    "#             Rel_Int = all_td[2].text.strip()\n",
    "#             if Obs_Wav != \"\" and Rel_Int != \"\":\n",
    "#                 All_Observed_Wavelength.append(Obs_Wav)\n",
    "#                 All_Relative_Intensities.append(Rel_Int)\n",
    "# pprint(All_Observed_Wavelength)\n",
    "\n",
    "# Tiens on remarque que la structure du HTML doit avoir un petite erreur car lors du print de All_Observed_Wavelength \n",
    "# on remarque qu'on print les bonnes colonnes avec les bonnes valeur mais, on a 1 fois le tableau 1, 2 fois le tableau 2, et finalement 3 fois le tableau\n",
    "# 3 ce qui nous indique que l'on peut parcourir une seul fois le tableau 1 et récupérer toutes les données.\n",
    "\n",
    "tbody = tbodies[1]\n",
    "for tr in tbody.find_all('tr'):\n",
    "    all_td = tr.find_all('td')\n",
    "    if len(all_td) >= 2:\n",
    "        obs_wav = all_td[0].text.strip()\n",
    "        rel_int = all_td[2].text.strip()\n",
    "        if obs_wav != \"\" and rel_int != \"\":\n",
    "            All_Observed_Wavelength.append(obs_wav)\n",
    "            All_Relative_Intensities.append(rel_int)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'wavelength' : All_Observed_Wavelength,\n",
    "    'intensities': All_Relative_Intensities,\n",
    "    'chemical' : 'O I'\n",
    "})\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bac455-bff9-4643-bb58-4da5843d6030",
   "metadata": {},
   "source": [
    "## Jonction entre spectre inconnu et ce qui le compose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48889965-5734-49f3-b1c3-5bfd932d229c",
   "metadata": {},
   "source": [
    "Ici le but va être d'utiliser les datasets réaliser dans la partie \"Spectre Chimique\" pour faire une proposition de la composition du spectre inconnu. Pour chaque paire élèment/ionization il faut fournir un indice de confiance de la présence du dis élèment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f025940-2537-4e6d-a747-2e50469c0e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
